<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>Audio Analysis - Video Anomaly Detection</title>
    <style>
        * { margin:0; padding:0; box-sizing:border-box; }
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #000000 0%, #19191a 100%);
            min-height:100vh;
            display:flex;
            align-items:center;
            justify-content:center;
            padding:20px;
        }
        .container {
            background:white; padding:40px; border-radius:15px;
            box-shadow:0 10px 40px rgba(0,0,0,0.2); max-width:600px; width:100%;
            text-align:center;
            opacity: 0.7;
            transition: opacity 0.3s ease-in-out;
        }
        .container:hover {
            opacity: 1;
        }
        h1 { color:#333; margin-bottom:10px; }
        p { color:#666; margin-bottom:30px; }
        .microphone { font-size:80px; margin:30px 0; }
        .btn {
            padding:15px 40px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color:white; border:none; border-radius:5px; font-size:18px;
            cursor:pointer; transition: transform 0.2s; margin:10px;
        }
        .btn:hover { transform: translateY(-2px); }
        .btn:disabled { opacity:0.5; cursor:not-allowed; }
        .btn-secondary { background:#6c757d; }
        .loading { display:none; margin-top:20px; color:#667eea; font-size:16px; }
        .instructions {
            background:#cfdae6; padding:20px; border-radius:10px; margin-top:30px; text-align:left;
        }
        .instructions h3 { color:#333; margin-bottom:10px; }
        .instructions ul { margin-left:20px; color:#666; }
        .instructions li { margin:5px 0; }
        
        .location-status {
            margin-top: 20px;
            padding: 12px;
            background: #f8f9fa;
            border-radius: 8px;
            font-size: 14px;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 8px;
            transition: all 0.3s ease;
            border: 1px solid #dee2e6;
        }
        .location-status.loading {
            color: #ffc107;
            background: #fff3cd;
            border-color: #ffeeba;
        }
        .location-status.success {
            color: #28a745;
            background: #d4edda;
            border-color: #c3e6cb;
        }
        .location-status.error {
            color: #dc3545;
            background: #f8d7da;
            border-color: #f5c6cb;
        }
        .location-status .spinner {
            width: 16px;
            height: 16px;
            border: 2px solid rgba(0, 0, 0, 0.1);
            border-top-color: currentColor;
            border-radius: 50%;
            animation: spin 0.8s linear infinite;
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Audio Analysis</h1>
        <p>Record audio using your microphone for speech-to-text transcription</p>

        <div class="microphone">üéôÔ∏è</div>

        <button class="btn" id="recordBtn">Start Recording</button>
        <button class="btn btn-secondary" onclick="window.location.href='/'">Back to Home</button>

        <div class="loading" id="loading">üéôÔ∏è Listening... Please speak clearly</div>

        <div id="locationStatus" class="location-status loading">
            <div class="spinner"></div>
            <span>Getting your location...</span>
        </div>

        <div class="instructions">
            <h3>Instructions:</h3>
            <ul>
                <li>Click "Start Recording" to begin</li>
                <li>Speak clearly into your microphone</li>
                <li>Click "Stop Recording" when done</li>
                <li>Wait for the transcription to complete</li>
                <li>Location is captured for emergency tracking</li>
            </ul>
        </div>
    </div>

    <script>
        let userLatitude = null;
        let userLongitude = null;
        let locationAttempted = false;

        let audioContext = null;
        let mediaStream = null;
        let recorderWorker = null;
        let recording = false;
        let audioData = [];

        const btn = document.getElementById('recordBtn');
        const loading = document.getElementById('loading');

        function updateLocationStatus(message, cssClass) {
            const statusDiv = document.getElementById('locationStatus');
            statusDiv.className = `location-status ${cssClass}`;
            
            if (cssClass === 'loading') {
                statusDiv.innerHTML = `<div class="spinner"></div><span>${message}</span>`;
            } else if (cssClass === 'success') {
                statusDiv.innerHTML = `<span>‚úì ${message}</span>`;
            } else if (cssClass === 'error') {
                statusDiv.innerHTML = `<span>‚ö†Ô∏è ${message}</span>`;
            }
        }

        function requestLocation() {
            if (!navigator.geolocation) {
                updateLocationStatus('Geolocation not supported', 'error');
                locationAttempted = true;
                return;
            }

            updateLocationStatus('Getting your location...', 'loading');

            navigator.geolocation.getCurrentPosition(
                (pos) => {
                    userLatitude = pos.coords.latitude;
                    userLongitude = pos.coords.longitude;
                    locationAttempted = true;
                    
                    const lat = userLatitude.toFixed(4);
                    const lon = userLongitude.toFixed(4);
                    updateLocationStatus(`Location: ${lat}, ${lon}`, 'success');
                    
                    console.log("‚úÖ Location acquired:", userLatitude, userLongitude);
                },
                (err) => {
                    locationAttempted = true;
                    console.error('Location error:', err);
                    
                    if (err.code === err.PERMISSION_DENIED) {
                        updateLocationStatus('Location permission denied', 'error');
                    } else if (err.code === err.POSITION_UNAVAILABLE) {
                        updateLocationStatus('Location unavailable', 'error');
                    } else if (err.code === err.TIMEOUT) {
                        updateLocationStatus('Location timeout', 'error');
                    } else {
                        updateLocationStatus('Failed to get location', 'error');
                    }
                },
                { enableHighAccuracy: true, timeout: 15000, maximumAge: 0 }
            );
        }

        // Initialize location on page load
        document.addEventListener("DOMContentLoaded", () => {
            requestLocation();
        });

        // Single event listener for record button
        btn.addEventListener('click', async () => {
            if (recording) {
                await stopRecordingAndUpload();
            } else {
                await startRecording();
            }
        });

        async function startRecording() {
            try {
                if (!locationAttempted) {
                    alert('Please wait for location detection to complete...');
                    return;
                }

                if (userLatitude === null || userLongitude === null) {
                    const proceed = confirm('Location not available. Record without location data?\n\n(Location may be required for emergency services)');
                    if (!proceed) {
                        return;
                    }
                }

                btn.disabled = true;
                loading.style.display = 'block';
                loading.textContent = 'Requesting microphone permission...';

                mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(mediaStream);

                const bufferSize = 4096;
                const processor = audioContext.createScriptProcessor(bufferSize, 1, 1);

                source.connect(processor);
                processor.connect(audioContext.destination);

                audioData = [];

                processor.onaudioprocess = (e) => {
                    const inputBuffer = e.inputBuffer.getChannelData(0);
                    audioData.push(new Float32Array(inputBuffer));
                };

                recorderWorker = { processor, source };
                recording = true;
                btn.textContent = 'Stop Recording';
                btn.disabled = false;
                loading.textContent = 'üéôÔ∏è Recording... Speak clearly';
            } catch (err) {
                console.error('getUserMedia error', err);
                alert('Microphone access denied or not available: ' + (err.message || err));
                btn.disabled = false;
                loading.style.display = 'none';
                cleanupLocal();
            }
        }

        async function stopRecordingAndUpload() {
            try {
                btn.disabled = true;
                loading.style.display = 'block';
                loading.textContent = 'Stopping... preparing audio';

                if (recorderWorker) {
                    try { recorderWorker.processor.disconnect(); } catch (e) { }
                    try { recorderWorker.source.disconnect(); } catch (e) { }
                }

                if (mediaStream) mediaStream.getTracks().forEach(t => t.stop());

                let length = 0;
                for (let i = 0; i < audioData.length; i++) length += audioData[i].length;
                const merged = new Float32Array(length);
                let offset = 0;
                for (let i = 0; i < audioData.length; i++) {
                    merged.set(audioData[i], offset);
                    offset += audioData[i].length;
                }

                const targetRate = 16000;
                const originalRate = audioContext.sampleRate;
                const downsampled = downsampleBuffer(merged, originalRate, targetRate);

                const wavBlob = encodeWAV(downsampled, targetRate);

                loading.textContent = 'Uploading audio...';

                const formData = new FormData();
                formData.append('audio', wavBlob, 'recording.wav');

                if (userLatitude !== null && userLongitude !== null) {
                    formData.append('latitude', userLatitude);
                    formData.append('longitude', userLongitude);
                    console.log('üìç Sending location:', userLatitude, userLongitude);
                } else {
                    console.log('‚ö†Ô∏è Uploading without location');
                }

                const resp = await fetch('/predict_audio', {
                    method: 'POST',
                    body: formData
                });

                if (!resp.ok) {
                    const t = await resp.text();
                    throw new Error(`Server returned ${resp.status}: ${t}`);
                }

                const data = await resp.json();

                if (data.error) {
                    alert('Error: ' + (data.detail ? `${data.error}\n${data.detail}` : data.error));
                } else if (data.text !== undefined) {
                    window.location.href = `/audio_result?text=${encodeURIComponent(data.text)}`;
                } else {
                    alert('Unexpected server response');
                }
            } catch (err) {
                console.error('Recording/upload error', err);
                alert('Error: ' + (err.message || err));
            } finally {
                cleanupLocal();
                btn.textContent = 'Start Recording';
                btn.disabled = false;
                loading.style.display = 'none';
                recording = false;
            }
        }

        function downsampleBuffer(buffer, sampleRate, outSampleRate) {
            if (outSampleRate === sampleRate) return buffer;
            if (outSampleRate > sampleRate) return buffer;
            
            const sampleRateRatio = sampleRate / outSampleRate;
            const newLength = Math.round(buffer.length / sampleRateRatio);
            const result = new Float32Array(newLength);
            let offsetResult = 0;
            let offsetBuffer = 0;
            
            while (offsetResult < result.length) {
                const nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio);
                let accum = 0, count = 0;
                for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {
                    accum += buffer[i];
                    count++;
                }
                result[offsetResult] = count ? (accum / count) : 0;
                offsetResult++;
                offsetBuffer = nextOffsetBuffer;
            }
            return result;
        }

        function floatTo16BitPCM(float32Array) {
            const buffer = new ArrayBuffer(float32Array.length * 2);
            const view = new DataView(buffer);
            let offset = 0;
            for (let i = 0; i < float32Array.length; i++, offset += 2) {
                let s = Math.max(-1, Math.min(1, float32Array[i]));
                view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            }
            return view;
        }

        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        function encodeWAV(samples, sampleRate) {
            const buffer = new ArrayBuffer(44 + samples.length * 2);
            const view = new DataView(buffer);

            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + samples.length * 2, true);
            writeString(view, 8, 'WAVE');
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(view, 36, 'data');
            view.setUint32(40, samples.length * 2, true);

            const pcmView = floatTo16BitPCM(samples);
            let offset = 44;
            for (let i = 0; i < pcmView.byteLength; i++) {
                view.setUint8(offset + i, pcmView.getUint8(i));
            }

            return new Blob([view], { type: 'audio/wav' });
        }

        function cleanupLocal() {
            try {
                if (recorderWorker) {
                    try { recorderWorker.processor.disconnect(); } catch (e) {}
                    try { recorderWorker.source.disconnect(); } catch (e) {}
                }
            } catch (e) {}
            try { if (mediaStream) mediaStream.getTracks().forEach(t => t.stop()); } catch (e) {}
            try { if (audioContext) audioContext.close(); } catch (e) {}
            recorderWorker = null;
            mediaStream = null;
            audioContext = null;
            audioData = [];
        }
    </script>
</body>
</html>